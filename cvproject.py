# -*- coding: utf-8 -*-
"""CVproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U3IO7oKXlMdr8dNnF9dBkgZpks0WB8I5
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import os

train_dir = os.path.join('/content/drive/MyDrive/Train')
validation_dir = os.path.join('/content/drive/MyDrive/Validation')
train_defective_dir = os.path.join('/content/drive/MyDrive/Train/Defective')
train_nondefective_dir = os.path.join('/content/drive/MyDrive/Train/Non defective')
validation_defective_dir = os.path.join('/content/drive/MyDrive/Validation/Defective')
validation_nondefective_dir = os.path.join('/content/drive/MyDrive/Validation/Non defective')

train_defective_fnames = os.listdir(train_defective_dir )
train_nondefective_fnames = os.listdir( train_nondefective_dir)

print(train_defective_fnames[:20])
print(train_nondefective_fnames[:20])

print('total training defective images :', len(os.listdir(train_defective_dir)))
print('total training non-defective images :', len(os.listdir(train_nondefective_dir)))
print('total validation defective images :', len(os.listdir( validation_defective_dir ) ))
print('total validation non-defective images :', len(os.listdir( validation_nondefective_dir) ))

# Parameters for our graph; we'll output images in a 10x10 configuration
nrows = 4
ncols = 4
# Index for iterating over images
pic_index = 0

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)

pic_index += 8
next_defective_pix = [os.path.join(train_defective_dir, fname)
                for fname in train_defective_fnames[pic_index-8:pic_index]]
next_nondefective_pix = [os.path.join(train_nondefective_dir, fname)
                for fname in train_nondefective_fnames[pic_index-8:pic_index]]


for i, img_path in enumerate(next_defective_pix+next_nondefective_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()

import cv2
from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras.applications.inception_v3 import InceptionV3

local_weights_file = '/content/drive/MyDrive/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'


pre_trained_model = InceptionV3(input_shape = (300,300, 3),
                                include_top = False,
                                weights = None)

pre_trained_model.load_weights(local_weights_file)

for layer in pre_trained_model.layers:
    layer.trainable = False
pre_trained_model.summary()

last_layer = pre_trained_model.get_layer('mixed7')
print('last layer output shape: ', last_layer.output.shape)
last_output = last_layer.output

from tensorflow.keras.preprocessing.image import ImageDataGenerator
#DATA PREPROCESSING

# Add our data-augmentation parameters to ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255.,
                                   rotation_range = 40,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255.,
                                   rotation_range = 40,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

# Flow training images in batches of 20 using train_datagen generator
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=20,
                                                    class_mode='binary',
                                                    target_size=(300,300))
# Flow validation images in batches of 20 using test_datagen generator
validation_generator =  test_datagen.flow_from_directory(validation_dir,
                                                         batch_size=20,
                                                         class_mode  = 'binary',
                                                         target_size = (300,300))

# from tensorflow.keras.optimizers import RMSprop

# # Flatten the output layer to 1 dimension
# x = layers.Flatten()(last_output)
# # Add a fully connected layer with 1,024 hidden units and ReLU activation
# x = layers.Dense(32, activation='relu')(x)
# # Add a dropout rate of 0.2
# x = layers.Dropout(0.2)(x)
# # Add a final sigmoid layer for classification
# x = layers.Dense(1, activation='sigmoid')(x)

# model = Model( pre_trained_model.input, x)

# model.compile(optimizer = 'Adam',
#               loss = 'binary_crossentropy',
#               metrics = ['accuracy'])
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Load the pre-trained InceptionV3 model (excluding top layer)
base_model = InceptionV3(
    weights='imagenet',
    include_top=False,
    input_shape=(300, 300, 3)
)

# Freeze all layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Build custom top layers
x = base_model.output
x = GlobalAveragePooling2D()(x)          # Global average pooling instead of Flatten
x = Dense(128, activation='relu')(x)     # Increased capacity
x = Dropout(0.5)(x)                       # Higher dropout to reduce overfitting
x = Dense(32, activation='relu')(x)      # Additional Dense layer
x = Dropout(0.2)(x)                       # Optional second dropout
predictions = Dense(1, activation='sigmoid')(x)  # Binary classification output

# Create the full model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.0001),       # Lower LR helps with transfer learning
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(train_generator,
                              validation_data=validation_generator,
                              epochs=25,
                              verbose=1)

model_save_name=model.save('mymodel.h5',history)
print('model save successfully')

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc      = history.history[     'accuracy' ]
val_acc  = history.history[ 'val_accuracy' ]
loss     = history.history[    'loss' ]
val_loss = history.history['val_loss' ]

epochs   = range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot  ( epochs,     acc )
plt.plot  ( epochs, val_acc )
plt.title ('Training and validation accuracy')
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot  ( epochs,     loss )
plt.plot  ( epochs, val_loss )
plt.title ('Training and validation loss'  )

# Predict on the validation set
Y_pred = model.predict(validation_generator)
y_pred = (Y_pred > 0.5).astype(int).flatten()  # Convert probabilities to binary

y_true = validation_generator.classes

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Defective', 'Non-Defective'])
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Get true labels
y_true = validation_generator.classes

# Calculate accuracy
accuracy = accuracy_score(y_true, y_pred)
print(f"Validation Accuracy: {accuracy * 100:.2f}%")

# Optional: Print classification report and confusion matrix
print("\nClassification Report:")
print(classification_report(y_true, y_pred))

print("Confusion Matrix:")
print(confusion_matrix(y_true, y_pred))

import cv2
import numpy as np
import matplotlib.pyplot as plt
img = cv2.imread('/content/drive/MyDrive/Test/Non defective/IMG_20201114_100023.jpg')
plt.imshow(img)
img = cv2.resize(img,(300,300))
img = np.reshape(img,[1,300,300,3])

classes = model.predict(img)

print(classes)
if classes>0.5:
    print("This Railway track has no fault")
else:
    print("This Railway track has fault")

img = cv2.imread('/content/drive/MyDrive/Test/Defective/IMG_20201114_102222.jpg')
plt.imshow(img)
img = cv2.resize(img,(300,300))
img = np.reshape(img,[1,300,300,3])

classes = model.predict(img)

print(classes)
if classes>0.5:
    print("This Railway track has no fault")
else:
    print("This Railway track has fault")

